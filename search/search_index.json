{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Parallel ML Docs This organization is from Georgia Tech, HPArch .","title":"Home"},{"location":"#welcome-to-parallel-ml-docs","text":"This organization is from Georgia Tech, HPArch .","title":"Welcome to Parallel ML Docs"},{"location":"camera/picamera/","text":"Using the PiCamera Module For using the PiCamera on a Raspberry Pi, you should, after connecting the camera to the Raspberry, update and upgrade your pi with: sudo apt-get update and sudo apt-get upgrade That may take some short time. Then, you have to enable the camera in the raspberry settings by: 'sudo raspi-config' Reboot the pi after that: sudo reboot Give some time for the pi to reboot and log again into it. Finally, test your camera with: raspistill -o image.jpg (it takes a picture and saves it as image.jpg ) After that, a new jpeg file should appear in your directory. General Helpfull information about PiCamera (https://picamera.readthedocs.io/en/release-1.12) Visualizing pictures via ssh If you want to display the images of image files in your computer, make sure to connect to the pi with: ssh -X pi@<pi_adress> (focus on the -X ) Install feh if you the don't have it yet: sudo apt-get install feh And finally do: feh <image_file>.jpg","title":"Using the PiCamera"},{"location":"camera/picamera/#using-the-picamera-module","text":"For using the PiCamera on a Raspberry Pi, you should, after connecting the camera to the Raspberry, update and upgrade your pi with: sudo apt-get update and sudo apt-get upgrade That may take some short time. Then, you have to enable the camera in the raspberry settings by: 'sudo raspi-config' Reboot the pi after that: sudo reboot Give some time for the pi to reboot and log again into it. Finally, test your camera with: raspistill -o image.jpg (it takes a picture and saves it as image.jpg ) After that, a new jpeg file should appear in your directory. General Helpfull information about PiCamera (https://picamera.readthedocs.io/en/release-1.12)","title":"Using the PiCamera Module"},{"location":"camera/picamera/#visualizing-pictures-via-ssh","text":"If you want to display the images of image files in your computer, make sure to connect to the pi with: ssh -X pi@<pi_adress> (focus on the -X ) Install feh if you the don't have it yet: sudo apt-get install feh And finally do: feh <image_file>.jpg","title":"Visualizing pictures via ssh"},{"location":"camera/webcam/","text":"Webcam Video/Image Install streamer: sudo apt-get install streamer Record video or capture streamer -q -c /dev/video0 -r 10 -t 00:00:20 -s 640x480 -o ~/test0000.jpeg streamer -q -c /dev/video0 -f rgb24 -t 00:01:30 -r 10 -s 640x480 -o ~/outfile.avi Convert to .mov to compress, then transfer. The options is set to work with Quick Time, but VLC works with any option (e.g., audio format and pixel format) ffmpeg -i outfile.avi -acodec libmp3lame -ab 192 -pix_fmt yuv420p -r 9 output.mov","title":"Webcam video/image"},{"location":"camera/webcam/#webcam-videoimage","text":"Install streamer: sudo apt-get install streamer Record video or capture streamer -q -c /dev/video0 -r 10 -t 00:00:20 -s 640x480 -o ~/test0000.jpeg streamer -q -c /dev/video0 -f rgb24 -t 00:01:30 -r 10 -s 640x480 -o ~/outfile.avi Convert to .mov to compress, then transfer. The options is set to work with Quick Time, but VLC works with any option (e.g., audio format and pixel format) ffmpeg -i outfile.avi -acodec libmp3lame -ab 192 -pix_fmt yuv420p -r 9 output.mov","title":"Webcam Video/Image"},{"location":"getting-started/setting-up-pi/","text":"Pre-Requisite Raspberry Pi can ONLY be accessed from lab's network. Connect to NETGEAR79 Wi-Fi with password 78zBJr!4bVdpaFIQ . Connect to Raspberry Pi Find IP of available Pi Go to 192.168.1.1 in your browser with username admin and password password to check IP of all connected Raspberry Pis. Under connected devices tab, you will be able to see the IP of all connected Raspberry Pis. Connect through SSH ssh pi@<ip> Use password raspberry for connection or for sudo command. Python Setup Python Environment We are using Python 2.7 for this project. PLEASE DO NOT CHANGE THE RASPBERRY PI's DEFAULT PYTHON SETTING. Package Installation pip is always recommended for Python package installations. A cleaner way would be using virtualenv , so that your environment won't interfere with others'.","title":"Connecting to Raspberry Pi"},{"location":"getting-started/setting-up-pi/#pre-requisite","text":"Raspberry Pi can ONLY be accessed from lab's network. Connect to NETGEAR79 Wi-Fi with password 78zBJr!4bVdpaFIQ .","title":"Pre-Requisite"},{"location":"getting-started/setting-up-pi/#connect-to-raspberry-pi","text":"Find IP of available Pi Go to 192.168.1.1 in your browser with username admin and password password to check IP of all connected Raspberry Pis. Under connected devices tab, you will be able to see the IP of all connected Raspberry Pis. Connect through SSH ssh pi@<ip> Use password raspberry for connection or for sudo command.","title":"Connect to Raspberry Pi"},{"location":"getting-started/setting-up-pi/#python-setup","text":"Python Environment We are using Python 2.7 for this project. PLEASE DO NOT CHANGE THE RASPBERRY PI's DEFAULT PYTHON SETTING. Package Installation pip is always recommended for Python package installations. A cleaner way would be using virtualenv , so that your environment won't interfere with others'.","title":"Python Setup"},{"location":"irobot/keyboard/","text":"Control with Keyboard Make sure Pi is connected to power and serial ssh -X pi@192.168.1.2 sudo chmod o+rw /dev/ttyUSB0 gtkterm Configure port to USB0 Change baud rate to 115200 python create2_cmds.py Click connect and type /dev/ttyUSB0 (the above) Press 'p' then 'f' The robot is now controllable To see data from sensors (power): - View -> Hexadecimal - Log -> to somelogfile.txt - Go to python and press 'z' to begin log stream - Do whatever (ML stuff) - Stop logging from log menu when done - translatorStream.py -> change file read name to somelogfile.txt (whatever name) - python translatorStream.py - done.txt contains voltage and current values","title":"Keyboard Control"},{"location":"irobot/keyboard/#control-with-keyboard","text":"Make sure Pi is connected to power and serial ssh -X pi@192.168.1.2 sudo chmod o+rw /dev/ttyUSB0 gtkterm Configure port to USB0 Change baud rate to 115200 python create2_cmds.py Click connect and type /dev/ttyUSB0 (the above) Press 'p' then 'f' The robot is now controllable To see data from sensors (power): - View -> Hexadecimal - Log -> to somelogfile.txt - Go to python and press 'z' to begin log stream - Do whatever (ML stuff) - Stop logging from log menu when done - translatorStream.py -> change file read name to somelogfile.txt (whatever name) - python translatorStream.py - done.txt contains voltage and current values","title":"Control with Keyboard"},{"location":"speech/deepspeech/","text":"Deepspeech on Raspberry Pi Requirements: have python3 installed with pip3 https://github.com/mozilla/DeepSpeech#using-the-python-package Run Deepspeech with Trained Model (use python deepspeech package) WARNING: this model is really big: 1.6 GB; so you cannot do this on raspberry pi Follow steps under Using Pre-trained mode on the github page (https://github.com/mozilla/DeepSpeech#using-the-python-package), using python package which are: Make a virtual environment: Pip3 install virtualenv if you don\u2019t have virtualenv python package yet (or pip) version virtualenv -p python3 $HOME/tmp/deepspeech-venv/ Instead of $HOME/tmp/deepspeech-venv, put the path of where you want the virtual environment to be made deepspeech-venv will be the name of the environment so change that if you want a different name Or just make a virtualenv how you normally do Activate the virtual environment Now the virtual environment is created with a bin folder with activate document source $HOME/tmp/deepspeech-venv/bin/activate This creates a virtual environment where you can install deepspeech related dependencies Now install deepspeech package on your local environment pip3 install deepspeech Using this: https://github.com/mozilla/DeepSpeech#getting-the-pre-trained-model, download the latest pre-trained deepspeech model: (You can use an older one if you want to) Linux: run this command in the directory you want to put the file: wget https://github.com/mozilla/DeepSpeech/releases/download/v0.5.0/deepspeech-0.5.0-models.tar.gz Others, just enter link into web browser, this will download the file. Then manually move the file to preferred directory Then, unzip the file using tar command tar xvfz deepspeech-0.5.0-models.tar.gz This creates a folder, called deepspeech-0.5.0-models Now download an audio file you want the model to do speech to text recognition Put this model in the preferred directory Go to the preferred directory on the command line and run this command: deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio my_audio_file.wav EXCEPT: replace my_audio_file.wav with your audio file and --lm and --trie tags are optional Replace models with deepspeech-0.5.0-models or with the name of the folder created from the download Making Your Own Model Next we tried to make our own model to see if we can reduce the model size: 1.) When running on a raspberry pi, go to the \"connecting to the raspberry pi\" docs to connect You would have to scp the newly trained model to the raspberry pi assuming trained model is small enough 2.) If you want to use a GPU, follow directions from the gpu slack channel for conection Using steps from https://github.com/mozilla/DeepSpeech#training-your-own-model: Make or activate your virtualenv for deepspeech Git clone DeepSpeech from the github git clone https://github.com/mozilla/DeepSpeech.git Install required dependencies from requirements.txt file, Run these commands cd deepspeech pip3 install -r requirements.txt If you are using gpu, use tensorflow gpu: pip3 uninstall tensorflow pip3 install 'tensorflow-gpu==1.13.1' Download voice training data from common voice: https://voice.mozilla.org/en/datasets; - Download the Tatoeba dataset - Go to the link, scroll down to the Tatoeba dataset, press more, and press download - Move it to your preferrred directory - Unzip the file The data is needs to be converted wav files. The data needs to be split into train, test, and dev data 3 csv files need to be created (for each split) which stores the wav_filename, wav_filesize, and transcript - Use import.py and untilA.csv to convert MP3 to WAV file while creating train.csv, dev.csv, and test.csv (The untilA.csv file tells where all the mp3 files are located) - Put \u2018import.py\u2019 and \u2018untilA.csv\u2019 in same folder - Install pydub (pydub will help convert MP3 to WAV) pip3 install pydub - (Optional) apt-get install ffmpeg - Edit import.py before you start running the code - Change the fullpath variable to the directory that has the audio files - For example, fullpath = \u2018/home/user/Download/tatoeba_audio_eng/tatoeba_audio_eng/audio\u2019 - Now, run import.py by python3 import.py - As a result, you will have the following files: new_names.csv train.csv dev.csv test.csv \u2018new_names.csv\u2019 is just a file that contains all wav file directories - Using ./Deepspeech.py to create your own model ./DeepSpeech.py --train_files /locate/directory/here/train.csv --dev_files /locate/directory/here/dev.csv --test_files /locate/directory/here/test.csv","title":"Deepspeech"},{"location":"speech/deepspeech/#deepspeech-on-raspberry-pi","text":"Requirements: have python3 installed with pip3 https://github.com/mozilla/DeepSpeech#using-the-python-package","title":"Deepspeech on Raspberry Pi"},{"location":"speech/deepspeech/#run-deepspeech-with-trained-model","text":"(use python deepspeech package) WARNING: this model is really big: 1.6 GB; so you cannot do this on raspberry pi Follow steps under Using Pre-trained mode on the github page (https://github.com/mozilla/DeepSpeech#using-the-python-package), using python package which are: Make a virtual environment: Pip3 install virtualenv if you don\u2019t have virtualenv python package yet (or pip) version virtualenv -p python3 $HOME/tmp/deepspeech-venv/ Instead of $HOME/tmp/deepspeech-venv, put the path of where you want the virtual environment to be made deepspeech-venv will be the name of the environment so change that if you want a different name Or just make a virtualenv how you normally do Activate the virtual environment Now the virtual environment is created with a bin folder with activate document source $HOME/tmp/deepspeech-venv/bin/activate This creates a virtual environment where you can install deepspeech related dependencies Now install deepspeech package on your local environment pip3 install deepspeech Using this: https://github.com/mozilla/DeepSpeech#getting-the-pre-trained-model, download the latest pre-trained deepspeech model: (You can use an older one if you want to) Linux: run this command in the directory you want to put the file: wget https://github.com/mozilla/DeepSpeech/releases/download/v0.5.0/deepspeech-0.5.0-models.tar.gz Others, just enter link into web browser, this will download the file. Then manually move the file to preferred directory Then, unzip the file using tar command tar xvfz deepspeech-0.5.0-models.tar.gz This creates a folder, called deepspeech-0.5.0-models Now download an audio file you want the model to do speech to text recognition Put this model in the preferred directory Go to the preferred directory on the command line and run this command: deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio my_audio_file.wav EXCEPT: replace my_audio_file.wav with your audio file and --lm and --trie tags are optional Replace models with deepspeech-0.5.0-models or with the name of the folder created from the download","title":"Run Deepspeech with Trained Model"},{"location":"speech/deepspeech/#making-your-own-model","text":"Next we tried to make our own model to see if we can reduce the model size: 1.) When running on a raspberry pi, go to the \"connecting to the raspberry pi\" docs to connect You would have to scp the newly trained model to the raspberry pi assuming trained model is small enough 2.) If you want to use a GPU, follow directions from the gpu slack channel for conection Using steps from https://github.com/mozilla/DeepSpeech#training-your-own-model: Make or activate your virtualenv for deepspeech Git clone DeepSpeech from the github git clone https://github.com/mozilla/DeepSpeech.git Install required dependencies from requirements.txt file, Run these commands cd deepspeech pip3 install -r requirements.txt If you are using gpu, use tensorflow gpu: pip3 uninstall tensorflow pip3 install 'tensorflow-gpu==1.13.1' Download voice training data from common voice: https://voice.mozilla.org/en/datasets; - Download the Tatoeba dataset - Go to the link, scroll down to the Tatoeba dataset, press more, and press download - Move it to your preferrred directory - Unzip the file The data is needs to be converted wav files. The data needs to be split into train, test, and dev data 3 csv files need to be created (for each split) which stores the wav_filename, wav_filesize, and transcript - Use import.py and untilA.csv to convert MP3 to WAV file while creating train.csv, dev.csv, and test.csv (The untilA.csv file tells where all the mp3 files are located) - Put \u2018import.py\u2019 and \u2018untilA.csv\u2019 in same folder - Install pydub (pydub will help convert MP3 to WAV) pip3 install pydub - (Optional) apt-get install ffmpeg - Edit import.py before you start running the code - Change the fullpath variable to the directory that has the audio files - For example, fullpath = \u2018/home/user/Download/tatoeba_audio_eng/tatoeba_audio_eng/audio\u2019 - Now, run import.py by python3 import.py - As a result, you will have the following files: new_names.csv train.csv dev.csv test.csv \u2018new_names.csv\u2019 is just a file that contains all wav file directories - Using ./Deepspeech.py to create your own model ./DeepSpeech.py --train_files /locate/directory/here/train.csv --dev_files /locate/directory/here/dev.csv --test_files /locate/directory/here/test.csv","title":"Making Your Own Model"}]}